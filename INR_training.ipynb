{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "gpu = False\n",
    "device = \"cuda\" if gpu else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data with some normalisation\n",
    "As the grid is fixed, we normalise X, Y, Z, T\n",
    "\n",
    "T might be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inr_src import return_dataset\n",
    "import inr_src as inr\n",
    "path = \"./data/test_data.npy\"\n",
    "ds, ds_test, nv, nv_y = inr.return_dataset(path, gpu=False)\n",
    "\n",
    "print(\"##########\\n X, Y, T\")\n",
    "print(ds.samples)\n",
    "print(\"##########\\n Z\")\n",
    "print(ds.targets)\n",
    "print(\"##########\\n Shape\")\n",
    "print(ds.targets.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Neural Representation\n",
    "\n",
    "Currently, different models are available: RFF or SIREN. I could also implement WIRES (based on wavelet functions).\n",
    "For these models, different archectures are available: \n",
    "\n",
    "The loss we are minimizing is the: $$\\mathcal{L} = ||f(x, y, t)  - z ||_2 + \\lambda_{xy}||\\frac{\\mathrm{d} f}{\\mathrm{d} xy}||_2 + \\lambda_{t}||\\frac{\\mathrm{d} f}{ \\mathrm{d} t}||_2 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/test_data.npy\"\n",
    "\n",
    "opt = inr.AttrDict()\n",
    "opt.path = path\n",
    "opt.gpu = gpu\n",
    "opt.fourier = True #False  #False\n",
    "opt.siren = False # True\n",
    "opt.name = \"RFF\"\n",
    "model_hp = inr.AttrDict()\n",
    "\n",
    "model_hp.fourier = opt.fourier\n",
    "model_hp.siren = opt.siren\n",
    "model_hp.verbose = True\n",
    "model_hp.epochs = 50\n",
    "\n",
    "model_hp.bs = 2**16\n",
    "model_hp.scale = 5\n",
    "model_hp.lr = 1e-5\n",
    "model_hp.output_size = 1\n",
    "\n",
    "if opt.siren:\n",
    "    print(\"Using siren\")\n",
    "    model_hp.architecture = \"siren\"\n",
    "    model_hp.siren_hidden_num = 5\n",
    "    model_hp.siren_hidden_dim = 1024\n",
    "    model_hp.siren_skip = True\n",
    "else:\n",
    "    model_hp.mapping_size = 512\n",
    "    model_hp.architecture = \"skip-5\"  # \"Vlarge\"\n",
    "    model_hp.activation = \"tanh\"\n",
    "\n",
    "model_hp.lambda_t = 0.0\n",
    "model_hp.lambda_xy = 0.0\n",
    "\n",
    "model, model_hp = inr.train(opt, model_hp, gpu=opt.gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you prefer to load the model\n",
    "import numpy as np\n",
    "import torch\n",
    "from inr_src.models import ReturnModel\n",
    "from inr_src.project_parser import AttrDict\n",
    "from inr_src.util_train import clean_hp\n",
    "\n",
    "opt = AttrDict()\n",
    "opt.name = \"RFF\"\n",
    "## From saved\n",
    "npz = np.load(f\"meta/{opt.name}.npz\")\n",
    "\n",
    "weights = f\"meta/{opt.name}.pth\"\n",
    "model_hp = AttrDict(npz)\n",
    "model_hp = clean_hp(model_hp)\n",
    "\n",
    "model = ReturnModel(\n",
    "    int(model_hp.input_size),\n",
    "    int(model_hp.output_size),\n",
    "    arch=str(model_hp.architecture),\n",
    "    args=model_hp,\n",
    ")\n",
    "model.load_state_dict(torch.load(weights))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some data visualisation\n",
    "## Some real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import ipywidgets as ipw\n",
    "import plotly.express as px\n",
    "\n",
    "# Visualisation the data set by tempoarl averaging of each month\n",
    "pc = np.load(\"data/test_data.npy\")\n",
    "q33 = np.quantile(pc[:,3], 0.33)\n",
    "q66 = np.quantile(pc[:,3], 0.66)\n",
    "pc_t0 = pc[pc[:,3] < q33]\n",
    "pc_t1 = pc[(pc[:,3] >= q33) & (pc[:,3] < q66)]\n",
    "pc_t2 = pc[(pc[:,3] >= q66)]\n",
    "\n",
    "for spc, title in [(pc_t0, \"Jan.\"), (pc_t1, \"Feb.\"), (pc_t2, \"Mar.\")]:\n",
    "\n",
    "    idx = np.random.choice(np.arange(spc.shape[0]), replace=False, size=int(1e5))\n",
    "    fig = px.scatter_3d(x=spc[idx,0], y=spc[idx,1], z=spc[idx,2],\n",
    "                color=spc[idx,3])\n",
    "    fig.update_layout(title=title, legend_title_text=\"Time\")\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model predicts Z from XYT of the trained points! (Should be good...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "xytz_ds = inr.XYTZ(\n",
    "        path,\n",
    "        train_fold=False,\n",
    "        train_fraction=0.0,\n",
    "        seed=42,\n",
    "        pred_type=\"pc\",\n",
    "        nv=model_hp.nv,\n",
    "        nv_targets=model_hp.nv_target,\n",
    "        gpu=gpu\n",
    "    )\n",
    "\n",
    "prediction = inr.predict_loop(xytz_ds, 2048, model, device=device)\n",
    "\n",
    "mse_norm = mean_squared_error(xytz_ds.targets, prediction)\n",
    "mae_norm = mean_absolute_error(xytz_ds.targets, prediction)\n",
    "\n",
    "norm_target = xytz_ds.targets * model_hp.nv_target[0,1] + model_hp.nv_target[0,0]\n",
    "norm_pred = prediction * model_hp.nv_target[0,1] + model_hp.nv_target[0,0]\n",
    "mse_unnorm = mean_squared_error(norm_target, norm_pred)\n",
    "mae_unnorm = mean_absolute_error(norm_target, norm_pred)\n",
    "\n",
    "print(f\"Normalised data -> MSE: {mse_norm:.5f} MAE: {mae_norm:.5f}\")\n",
    "print(f\"True Z values ->   MSE: {mse_unnorm:.3f} MAE: {mae_unnorm:.3f}\")\n",
    "\n",
    "q33 = np.quantile(xytz_ds.samples[:,2], 0.33)\n",
    "q66 = np.quantile(xytz_ds.samples[:,2], 0.66)\n",
    "\n",
    "idx_0 = xytz_ds.samples[:,2] < q33\n",
    "idx_1 = (xytz_ds.samples[:,2] >= q33) & (xytz_ds.samples[:,2] < q66)\n",
    "idx_2 = (xytz_ds.samples[:,2] >= q66)\n",
    "\n",
    "for idx, title in [(idx_0, \"Jan.\"), (idx_1, \"Feb.\"), (idx_2, \"Mar.\")]:\n",
    "    samples = xytz_ds.samples[idx] * model_hp.nv[:,1] + model_hp.nv[:,0]\n",
    "    pred = prediction[idx,0] * model_hp.nv_target[0,1] + model_hp.nv_target[0,0]\n",
    "\n",
    "    idx = np.random.choice(np.arange(samples.shape[0]), replace=False, size=int(1e5))\n",
    "    fig = px.scatter_3d(x=samples[idx,0], y=samples[idx,1], z=pred[idx],\n",
    "                color=samples[idx,2])\n",
    "    fig.update_layout(title=title, legend_title_text=\"Time\")\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting along the grid with \"t = middle of the month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linear grid for plotting\n",
    "#Capture a month\n",
    "q16 = np.quantile(pc[:,3], 0.1666)\n",
    "q50 = np.quantile(pc[:,3], 0.50)\n",
    "q83 = np.quantile(pc[:,3], 0.8333)\n",
    "\n",
    "dataset16 = inr.XYTZ_grid(pc, q16, nv=model_hp.nv, step_grid=0.01, gpu=gpu)\n",
    "dataset50 = inr.XYTZ_grid(pc, q50, nv=model_hp.nv, step_grid=0.01, gpu=gpu)\n",
    "dataset83 = inr.XYTZ_grid(pc, q83, nv=model_hp.nv, step_grid=0.01, gpu=gpu)\n",
    "nv = np.array(model_hp.nv)\n",
    "nv_target = np.array(model_hp.nv_target)\n",
    "XYT16 = dataset16.samples * nv[:,1] + nv[:,0]\n",
    "device = \"cuda\" if gpu else \"cpu\"\n",
    "# Predict along the grid\n",
    "preds16 = inr.predict_loop(dataset16, 2048, model, device=device)\n",
    "preds50 = inr.predict_loop(dataset50, 2048, model, device=device)\n",
    "preds83 = inr.predict_loop(dataset83, 2048, model, device=device)\n",
    "\n",
    "for spred, title in [(preds16, \"Jan.\"), (preds50, \"Feb.\"), (preds83, \"Mar.\")]:\n",
    "    spred_z = spred * nv_target[0,1] + nv_target[0,0]\n",
    "    fig = px.scatter_3d(x=XYT16[:,0], y=XYT16[:,1], z=spred_z[:,0],\n",
    "                color=spred_z[:,0])\n",
    "    fig.update_layout(title=title, legend_title_text=\"Time\")\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
